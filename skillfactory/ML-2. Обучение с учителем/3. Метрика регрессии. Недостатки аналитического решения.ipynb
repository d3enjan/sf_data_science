{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Метрика — это численное выражение качества моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества решения задачи регрессии существует множество метрик. Давайте рассмотрим самые основные и часто используемые."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> МЕТРИКИ РЕГРЕССИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Средняя абсолютная ошибка — MAE (Mean Absolute Error)**\n",
    "\n",
    "Это самый простой и уже знакомый вам показатель. Чтобы посчитать данную метрику, нужно найти все остатки (разницы между предсказанным значением и реальным), взять от каждого из них модуль, сложить их и поделить на количество. Иными словами, нам нужно найти среднее арифметическое модуля отклонения предсказанного значения от реального.\n",
    "$$MAE = \\frac{\\sum_{i=1}^{n}\\left | y_{i} - \\hat{y_{i}} \\right |}{n}$$\n",
    "\n",
    "Данная метрика интерпретируется очень легко: это число показывает, насколько в среднем наша модель ошибается. Чем меньше значение метрики, тем лучше.\n",
    "\n",
    "$$MAE = \\frac{\\left | 24.0-29.82 \\right |+\\left | 21.6-25.87 \\right |+\\left | 4.7-30.73 \\right |+\\left | 33.4-31.76 \\right |+\\left | 36.2-29.49 \\right |}{5} = 4.482 \\left [ тыс. \\$ \\right ]$$\n",
    "\n",
    "То есть для нашего примера из пяти наблюдений в среднем модель ошибается на 4.482 тысячи долларов.\n",
    "\n",
    "Много ли это? Хороший вопрос, на который без эксперта-оценщика недвижимости будет сложно дать ответ. Однако можно попробовать посчитать ошибку в процентах, ведь в процентах всё воспринимается легче, и для этого нам пригодится следующая метрика — MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Средняя абсолютная ошибка в процентах — MAPE (Mean Absolute Percent Error)**\n",
    "\n",
    "Для её вычисления мы делим модуль разницы между предсказанием алгоритма и истинным значением на истинное значение. Затем складываем все результаты (для каждого объекта), делим на количество и умножаем на 100 %.\n",
    "\n",
    "$$MAPE = \\sum_{i=1}^{n} \\frac{\\left | y_{i} - \\hat{y_{i}} \\right |}{\\left | y_{i} \\right |} \\frac{100\\%}{n}$$\n",
    "\n",
    "Эта метрика показывает, на сколько процентов в среднем наше предсказание отклоняется от реального значения. Эта метрика отлично показывает себя в задачах, когда неизвестно, какое значение целевого показателя считать приемлемым.\n",
    "\n",
    "Например, средняя ошибка — 2 тысячи долларов. Это много или мало? Смотря для чего... А вот средняя ошибка, равная 80 % — это много или мало? Определённо много.\n",
    "\n",
    "$$M A P E=\\left(\\frac{|24.0-29.82|}{|24.0|}+\\frac{|21.6-25.87|}{|21.6|}+\\frac{|34.7-30.73|}{|34.7|}+\\frac{|33.4-31.76|}{|33.4|}+\\frac{|36.2-29.49|}{|36.2|}\\right) \\frac{100 \\%}{5}=15.781 \\%$$\n",
    "\n",
    "Таким образом, на первых пяти наблюдениях модель в среднем ошибается на 15.781 %. Это довольно неплохой результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Средняя квадратическая ошибка — MSE**\n",
    "\n",
    "Данный показатель мы используем в линейной регрессии в качестве функции потерь, но ничто не мешает нам также использовать его и в качестве метрики.\n",
    "\n",
    "Логика вычисления данной ошибки очень похожа на предыдущую. Разница лишь в том, что вместо модуля разности между предсказанным и реальным значениями мы берём квадрат этого модуля:\n",
    "$$MSE = \\frac{\\sum_{i=1}^{n}(y_{i} - \\hat{y_{i}})^{2}}{n}$$\n",
    "\n",
    "Данная метрика хуже поддаётся интерпретации, чем предыдущая, так как измеряется не в единицах, а в квадратах единиц. Она чаще используется для внутреннего обсуждения между дата-сайентистами, заказчику такая метрика может быть непонятна.\n",
    "$$M S E=\\frac{(24.0-29.82)^{2}+(21.6-25.87)^{2}+(34.7-30.73)^{2}+(33.4-31.76)^{2}+(36.2-29.49)^{2}}{5}=22.116\\left[(\\text { тыс. } \\$)^{2}\\right]$$\n",
    "\n",
    "Таким образом, для нашего примера квадрат отклонения составляет 22.116 тысяч долларов в квадрате.\n",
    "\n",
    "Согласитесь, не очень понятно, о чём идет речь. Однако данная метрика является популярной, так как позволяет «штрафовать» модель за очень большие ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что значит «штрафовать»?** \n",
    "\n",
    "Например, расхождение в 200 единиц в метрике MSE воспринимается как , а в метрике MAE это расхождение воспринимается как 200. Поэтому, если у нас есть две модели, но одна из них допускает большие ошибки, эти ошибки становятся ещё больше при расчёте метрики MSE, и нам легче сравнить модели между собой.\n",
    "\n",
    "Но в то же время это и проклятие MSE. Если в данных присутствуют выбросы, метрика может быть необъективной. Если модель будет утверждать, что цена здания — 30 тысяч долларов, а в наборе данных ему соответствует цена в 3 миллиона долларов, то при возведении такой ошибки в квадрат получится 9 миллионов, что может сбить с толку исследователя. **Необходимо скептически относиться к данной метрике**, если вы не проводили исследование данных на предмет **наличия выбросов**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корень из средней квадратической ошибки — RMSE (Root Mean Squared Error)**\n",
    "\n",
    "Для получения RMSE надо просто извлечь квадратный корень из MSE:\n",
    "$$RMSE = \\sqrt{MSE} = \\sqrt{\\frac{\\sum_{i=1}^{n}(y_{i} - \\hat{y_{i}})^{2}}{n}}$$\n",
    "\n",
    "Корень извлекается для того, чтобы привести размерности ответов и ошибок в соответствие и сделать метрику более понятной.\n",
    "$$RMSE = \\sqrt{22.116} = 4.702 \\left [ тыс. \\$ \\right ]$$\n",
    "\n",
    "Преимущества и недостатки этой метрики такие же, как и у MSE, к преимуществам добавляется только понятная размерность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Коэффициент детерминации ($R^{2}$)**\n",
    "\n",
    "Все рассматриваемые ранее метрики имели масштаб от 0 до +∞. Чем это плохо?\n",
    "\n",
    "А что если нам скажут, что MSE для модели составляет 32? Должны ли мы улучшить модель, или она достаточно хороша? А что если MSE = 0.4?\n",
    "\n",
    "На самом деле, трудно понять, хороша модель или нет, не сравнив её показатели с теми же показателями других моделей.\n",
    "\n",
    "Коэффициент детерминации, или $R^{2}$, является ещё одним показателем, который мы можем использовать для оценки модели. Он тесно связан с MSE, но его преимущество в том, что $R^{2}$ всегда находится в промежутке между -∞ и 1.\n",
    "$$R^{2} = 1 - \\frac{MSE}{MSE_{mean}},$$\n",
    "где\n",
    "$$MSE_{mean} = \\frac{\\sum_{i=1}^{n}(y_{i} - \\bar{y})^{2}}{n},$$\n",
    "где $\\bar{y}$ — среднее по вектору правильных ответов.\n",
    "\n",
    "То есть $R^{2}$ показывает, насколько наша модель лучше, чем если бы все предсказания были средним по правильным ответам.\n",
    "\n",
    "Посмотрим, как считается $R^{2}$. Сначала рассчитаем среднее по правильным ответам:\n",
    "$$\\bar{y} = \\frac{24.0+21.6+34.7+33.4+36.2}{5} = 29.98$$\n",
    "\n",
    "Теперь рассчитаем $MSE_{mean}$:\n",
    "$$M S E_{\\text {mean }}=\\frac{(24.0-29.98)^{2}+(21.6-29.98)^{2}+(34.7-29.98)^{2}+(33.4-29.98)^{2}+(36.2-29.98)^{2}}{5}=35.72$$\n",
    "И, наконец, сам $R^{2}$:\n",
    "$$R^{2} = 1 - \\frac{22.116}{35.72} = 0.38$$\n",
    "\n",
    "Есть ещё одна интерпретация данной метрики. Статистически показатель $R^{2}$ описывает, какую долю информации о зависимости (дисперсии) смогла уловить модель.\n",
    "\n",
    "**Удовлетворительным $R^{2}$ считается показатель выше 0.5: чем ближе к 1, тем лучше. Отрицательные значения $R^{2}$ говорят о том, что построенная модель настолько плоха, что лучше было бы присвоить всем ответам среднее значение.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE mean_absolute_error()\n",
    "\n",
    "MAPE mean_absolute_percentage_error()\n",
    "\n",
    "MSE\tmean_square_error()\n",
    "\n",
    "RMSE Отдельная функция отсутствует, но можно извлечь корень из результата функции mean_square_error()\n",
    "\n",
    "$R^{2}$  r2_score()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> РАСЧЁТ МЕТРИК НА PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настало время проверить качество построенных нами ранее моделей линейной регрессии: lr_lstat и lr_full.\n",
    "\n",
    "Весь набор функций для вычисления метрик в sklearn находится в модуле [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). Давайте его импортируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_absolute_error() — расчёт MAE;\n",
    "# mean_square_error() — расчёт MSE;\n",
    "# mean_absolute_percentage_error() — расчёт MAPE;\n",
    "# r2_score() — расчёт коэффициента детерминации ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Примечание. Для расчёта метрики RMSE нет специальной функции, однако мы знаем, что для её расчёта достаточно извлечь квадратный корень из MSE.\n",
    "\n",
    "Из-за особенностей реализации функция mean_absolute_percentage_error() возвращает результат не в процентах, а в долях. Чтобы отобразить результат в процентах, необходимо умножить его на 100.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Давайте вычислим метрики и выведем их на экран, округлив до третьего знака после запятой. Начнём с модели lr_lstat: сделаем предсказание на основании признака LSTAT и передадим истинные и предсказанные медианные цены в функции для расчёта метрик:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\d3en\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston()\n",
    "\n",
    "#создаём DataFrame из загруженных numpy-матриц\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "#добавляем в таблицу столбец с целевой переменной\n",
    "boston_data['MEDV'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston_data[['LSTAT']] #матрица наблюдений\n",
    "y = boston_data['MEDV'] #вектор правильных ответов\n",
    "\n",
    "lr_lstat = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_lstat.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 4.505 thou. $\n",
      "RMSE score: 6.203 thou. $\n",
      "MAPE score: 21.352 %\n",
      "R2 score: 0.544\n"
     ]
    }
   ],
   "source": [
    "#Делаем предсказание по признаку LSTAT\n",
    "y_predict_lstat = lr_lstat.predict(boston_data[['LSTAT']])\n",
    "#Рассчитываем MAE\n",
    "print('MAE score: {:.3f} thou. $'.format(metrics.mean_absolute_error(y, y_predict_lstat)))\n",
    "#Рассчитываем RMSE\n",
    "print('RMSE score: {:.3f} thou. $'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_lstat))))\n",
    "#Рассчитываем MAPE\n",
    "print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_lstat) * 100))\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_lstat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проделываем ту же самую операцию для второй модели линейной регрессии, lr_full:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']\n",
    "#Создаём объект класса LinearRegression\n",
    "lr_full = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_full.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 3.271 thou. $\n",
      "RMSE score: 4.679 thou. $\n",
      "MAPE score: 16.417 %\n",
      "R2 score: 0.741\n"
     ]
    }
   ],
   "source": [
    "#Делаем предсказание по всем признакам\n",
    "y_predict_full = lr_full.predict(boston_data[features])\n",
    "#Рассчитываем MAE\n",
    "print('MAE score: {:.3f} thou. $'.format(metrics.mean_absolute_error(y, y_predict_full)))\n",
    "#Рассчитываем RMSE\n",
    "print('RMSE score: {:.3f} thou. $'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_full))))\n",
    "#Рассчитываем MAPE\n",
    "print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_full) * 100))\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_full)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним полученные результаты:\n",
    "\n",
    "MAE: в среднем первая модель ошибается на  4.505 тыс. долларов, а вторая — на 3.271 тыс. долларов.\n",
    "RMSE : среднеквадратичное отклонение первой модели от истинных ответов составляет 6.203 тыс. долларов, а второй — 4.679.\n",
    "MAPE : первая модель ошибается на 21.352 %, а вторая — на 16.417 %.\n",
    "R2 : доля объясняемой информации (дисперсии), которую улавливает первая модель, — 0.544, а вторая — 0.741.\n",
    "Очевидно, что по всем метрикам вторая модель, построенная на основе всех признаков в данных, превосходит первую.\n",
    "\n",
    "✍ Следует отметить, что для задач регрессии существует множество метрик, и мы рассмотрели только наиболее распространённые из них. Весь список метрик и их расчёт в [sklearn](https://scikit-learn.ru/3-3-metrics-and-scoring-quantifying-the-quality-of-predictions/#regression-metrics) вы можете найти здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score: 5.75\n"
     ]
    }
   ],
   "source": [
    "# Задание 3.2\n",
    "# У вас есть истинные ответы y_true = [1.23, 2.35, 2.75] и предсказания модели y_pred = [1.01, 12.3, 2.74]. Посчитайте метрику RMSE, ответ округлите до двух знаков после точки-разделителя.\n",
    "y_true = [1.23, 2.35, 2.75]\n",
    "y_pred = [1.01, 12.3, 2.74]\n",
    "print('RMSE score: {:.2f}'.format(np.sqrt(metrics.mean_squared_error(y_true, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Задание 3.3\n",
    "\n",
    "# Чему равен коэффициент детерминации на следующих данных?\n",
    "# Истинные ответы: y_true = [22.4, 20.6, 23.9, 22.0, 11.9]\n",
    "# Предсказанные ответы: y_pred = [20.5, 20.2, 20.3, 19.0, 11.0]\n",
    "# Ответ округлите до двух знаков после точки-разделителя.\n",
    "y_true = [22.4, 20.6, 23.9, 22.0, 11.9]\n",
    "y_pred = [20.5, 20.2, 20.3, 19.0, 11.0]\n",
    "\n",
    "print('R2 score: {:.2f}'.format(metrics.r2_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> НЕДОСТАТКИ АНАЛИТИЧЕСКОГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Существует теорема [Гаусса-Маркова](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%B0_%E2%80%94_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D0%B0), которая говорит о том, что, если выполнены все условия теоремы, МНК всегда находит оптимальные оценки параметров. Мы ещё вернемся к этой теореме, когда будем говорить об МНК в модулях по линейной алгебре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надо всего лишь перемножить матрицы между собой и получить ответ\n",
    "**Оказывается, у такого простого подхода есть один большой минус — это работа с большим количеством признаков.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Второй недостаток МНК — это невозможность инкрементального обучения, или обучения в режиме реального времени.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третий недостаток МНК больше теоретический и заключается в том, что матрица $Q = (X^{T}X)^{-1}$ в результате вычислений может не существовать. Это связано с математическими особенностями вычисления обратной матрицы, которые мы рассмотрим далее в курсе. \n",
    "\n",
    "Причина этой проблемы — мультиколлинеарность факторов (сильная корреляционная связь). Из-за этого коэффициенты линейной регрессии становятся слишком большими и модель становится неустойчивой. \n",
    "\n",
    "Проблема решается с помощью регуляризации."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aef7f665a0694191b93f381ff9bf3fa49787cf0440ec035fed5813d2b4b57be1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
